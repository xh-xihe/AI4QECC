{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606c26f8",
   "metadata": {},
   "source": [
    "# CWS / 子空间量子纠错码在非对称信道下的数值构造（Stiefel 流形优化 + 可选循环对称 k=0）\n",
    "\n",
    "本 Notebook 来自你提供的脚本 **`stifiel_cyclic_print.py`** 的逐行拆解与“讲稿化”整理，并保持原始代码逻辑可直接运行。主要目标：\n",
    "\n",
    "1. **构造一个 $n=L$ 量子比特系统上的 $K$ 维码空间**（一个子空间），用等距嵌入 $U\\in\\mathbb{C}^{2^L\\times K}$ 表示；\n",
    "2. 给定一个 **误差算符集合** $\\mathcal{E}$（可切换：`orig/E1/E2/E3`，或按表格规格 `d='2'/'asym'` 生成），验证/逼近 **Knill–Laflamme (KL) 条件**：\n",
    "   - **detect（检测级）**：对每个 $E\\in\\mathcal{E}\\setminus\\{I\\}$，要求 $P E P \\propto P$；\n",
    "   - **correct（纠错级）**：对每个 $E_a,E_b\\in\\mathcal{E}$，要求 $P E_a^\\dagger E_b P \\propto P$；\n",
    "3. 通过 **Stiefel 流形优化**（`numqi.manifold.Stiefel`）寻找 $U$，并在扫描 $\\lambda^{*2}$（目标参数）时：\n",
    "   - 实时记录优化历史；\n",
    "   - 对每个目标点选出“**最优可行**”解并打印；\n",
    "   - 画出曲线并保存 `png/csv` 摘要；\n",
    "4. （可选）加入 **循环平移对称（cyclic symmetry，k=0）**：把码空间限制在循环不变子空间中，显著降维，加速搜索。\n",
    "\n",
    "> 注：脚本内部把所有算符都转为稠密 `torch.complex128` 张量；当 $L$ 稍大（例如 $L\\ge 7$）会非常吃内存/时间。请根据机器资源调整参数。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51588807",
   "metadata": {},
   "source": [
    "## 0. 依赖与运行环境\n",
    "\n",
    "脚本依赖：\n",
    "\n",
    "- `numpy`\n",
    "- `torch`\n",
    "- `scipy`（`scipy.sparse` 用于构造稀疏 Pauli 张量积矩阵）\n",
    "- `matplotlib`\n",
    "- `numqi`（提供 Stiefel 流形参数化与优化器）\n",
    "\n",
    "如果你是 Conda 环境，典型安装方式（示例）：\n",
    "```bash\n",
    "pip install numpy scipy matplotlib\n",
    "pip install torch --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install numqi\n",
    "```\n",
    "\n",
    "> Notebook 中我们尽量保持与原脚本一致；若你想把“稀疏矩阵”一路保留到损失计算处，可进一步做稀疏/块对角优化，但那会改动较大，不在本整理范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 0. 基础导入 & 线程设置 =====\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import combinations\n",
    "from matplotlib.ticker import LogLocator, ScalarFormatter\n",
    "\n",
    "import numqi\n",
    "\n",
    "# 线程：与原脚本保持一致（可按需改）\n",
    "os.environ['MKL_NUM_THREADS'] = '12'\n",
    "os.environ['OMP_NUM_THREADS'] = '12'\n",
    "if torch.get_num_threads() != 12:\n",
    "    torch.set_num_threads(12)\n",
    "\n",
    "print(\"[setup] PyTorch threads =\", torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdace8",
   "metadata": {},
   "source": [
    "## 1. 统一配置区（你最常改的部分）\n",
    "\n",
    "原脚本把配置分成两套：\n",
    "\n",
    "- **新风格（按表格规格）**：`USE_TABLE_SPEC=True`  \n",
    "  通过 `(n=L, K, d, r)` 生成误差集合：\n",
    "  - `d='2'`：对称误差集 $\\{I\\}\\cup\\{X_i,Y_i,Z_i\\}$\n",
    "  - `d='asym', r=None`：混合非对称：$\\{I\\}\\cup\\{X_i,Y_i,Z_i\\}\\cup\\{XX,ZZ,XZ,ZX\\}$\n",
    "  - `d='asym', r>=1`：$\\{I\\}\\cup\\{X_i,Y_i\\}\\cup Z_{\\le r}$\n",
    "\n",
    "- **旧风格（手选误差集模式）**：`ERROR_SET_MODE='orig'|'E1'|'E2'|'E3'`\n",
    "\n",
    "此外还有：\n",
    "\n",
    "- `KL_LEVEL='detect'|'correct'`\n",
    "- `lambda2_list`：扫描的 $\\lambda^{*2}$ 网格\n",
    "- `optim_kwargs`：numqi 优化器参数（重复次数/阈值等）\n",
    "- `constraint_threshold`：判断“可行解”的阈值（offdiag+diag 小于该阈值才算满足 KL 约束）\n",
    "\n",
    "以及新增的循环对称选项：\n",
    "\n",
    "- `USE_CYCLIC_SYM=False/True`（目前仅实现 `k=0`）\n",
    "\n",
    "下面给出一个**可直接运行**的参数块，并提供一个更快的“烟雾测试（smoke test）”配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f26b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) 表格规格 / 误差集规格 =====\n",
    "USE_TABLE_SPEC = True\n",
    "TABLE_N = 5          # n = L\n",
    "TABLE_K = 3          # 码空间维 K\n",
    "TABLE_D = 'asym'     # '2' or 'asym'\n",
    "TABLE_R = 2          # r；表里“–”可用 None\n",
    "\n",
    "# 旧风格（当 USE_TABLE_SPEC=False 时生效）\n",
    "ERROR_SET_MODE = 'orig'   # 'orig'|'E1'|'E2'|'E3'\n",
    "\n",
    "# ===== 2) 统一 L 与 K =====\n",
    "L = TABLE_N if USE_TABLE_SPEC else 6\n",
    "CODE_K = TABLE_K\n",
    "\n",
    "# ===== 3) KL 级别 =====\n",
    "KL_LEVEL = 'detect'         # 'detect' 或 'correct'\n",
    "DROP_IDENTITY_IN_DETECT = True\n",
    "\n",
    "# ===== 4) 扫描 λ*² 的网格 =====\n",
    "lambda2_list = np.linspace(0.0, 1.5, 100)\n",
    "# 确保关键点在网格中（可选）\n",
    "for x_ins in (0.6, 1.0):\n",
    "    if x_ins not in lambda2_list:\n",
    "        lambda2_list = np.insert(lambda2_list, np.searchsorted(lambda2_list, x_ins), x_ins)\n",
    "\n",
    "# ===== 5) 优化器超参 =====\n",
    "optim_kwargs = dict(\n",
    "    theta0='uniform',\n",
    "    num_repeat=50,\n",
    "    tol=1e-15,\n",
    "    print_freq=0,\n",
    "    early_stop_threshold=1e-14,\n",
    ")\n",
    "constraint_threshold = 1e-12\n",
    "\n",
    "# ===== 6) 循环对称限制（可选）=====\n",
    "USE_CYCLIC_SYM = False      # True = 限制到 cyclic k=0 子空间\n",
    "CYCLIC_SECTOR = 'k0'\n",
    "\n",
    "# ===== 7) 一键切换：快速 smoke test（建议第一次先跑这个）=====\n",
    "SMOKE_TEST = False\n",
    "if SMOKE_TEST:\n",
    "    lambda2_list = np.array([0.0, 0.2, 0.6, 1.0])\n",
    "    optim_kwargs = dict(theta0='uniform', num_repeat=5, tol=1e-12, print_freq=0, early_stop_threshold=1e-10)\n",
    "    constraint_threshold = 1e-9\n",
    "\n",
    "print(f\"[config] L={L}, CODE_K={CODE_K}, KL={KL_LEVEL}, TABLE(d={TABLE_D}, r={TABLE_R}, K={TABLE_K}), cyclic={USE_CYCLIC_SYM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba68c1",
   "metadata": {},
   "source": [
    "## 2. Pauli 张量积算符的构造（稀疏）\n",
    "\n",
    "我们用标准 Pauli：\n",
    "\n",
    "- $X=\\begin{pmatrix}0&1\\\\1&0\\end{pmatrix}$\n",
    "- $Y=\\begin{pmatrix}0&-i\\\\i&0\\end{pmatrix}$\n",
    "- $Z=\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}$\n",
    "\n",
    "对 $L$ 比特系统，单比特算符 $X_j$ 表示在第 $j$ 个比特上作用 $X$，其余为 $I$：\n",
    "\\[\n",
    "X_j = I^{\\otimes (j-1)} \\otimes X \\otimes I^{\\otimes (L-j)}.\n",
    "\\]\n",
    "\n",
    "这里用 `scipy.sparse` 构造稀疏矩阵，避免在“生成误差集合”阶段就爆内存；但注意随后优化时会把所有算符转为稠密 `torch.complex128` 张量（这一步才是主要内存开销）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5adb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2. Pauli & tensor-product helpers (sparse) =====\n",
    "sx = np.array([[0.0, 1.0], [1.0, 0.0]], dtype=complex)\n",
    "sy = np.array([[0, -1j], [1j, 0]], dtype=complex)\n",
    "sz = np.array([[1.0, 0.0], [0.0, -1.0]], dtype=complex)\n",
    "\n",
    "_s = np.zeros((4, 2, 2), dtype=complex)  # 0:I, 1:X, 2:Y, 3:Z\n",
    "_s[0, :, :] = np.eye(2, dtype=complex)\n",
    "_s[1, :, :] = sx\n",
    "_s[2, :, :] = sy\n",
    "_s[3, :, :] = sz\n",
    "\n",
    "def identity_n(L: int):\n",
    "    \"\"\"Return I^(tensor L) as a csr sparse matrix.\"\"\"\n",
    "    return csr_matrix(sp.eye(2**L, dtype=complex, format='csr'))\n",
    "\n",
    "def sigma(i: int, j: int, L: int):\n",
    "    \"\"\"\n",
    "    Build a single-qubit Pauli on an L-qubit register as a sparse matrix.\n",
    "\n",
    "    i: 0->I, 1->X, 2->Y, 3->Z\n",
    "    j: 1..L indicates the qubit index (1-based). If j==0, return I^(tensor L).\n",
    "    \"\"\"\n",
    "    if j == 0:\n",
    "        return identity_n(L)\n",
    "    I2 = np.eye(2, dtype=complex)\n",
    "    mat = _s[i] if j == 1 else I2\n",
    "    for k in range(2, L+1):\n",
    "        mat = np.kron(mat, _s[i] if k == j else I2)\n",
    "    return csr_matrix(mat)\n",
    "\n",
    "def sigmax(j, L): return sigma(1, j, L)\n",
    "def sigmay(j, L): return sigma(2, j, L)\n",
    "def sigmaz(j, L): return sigma(3, j, L)\n",
    "\n",
    "print(\"[sanity] Hilbert dim =\", 2**L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a013d",
   "metadata": {},
   "source": [
    "## 3. 误差集合（Error sets）\n",
    "\n",
    "脚本支持两种方式构造误差集合 $\\mathcal{E}$：\n",
    "\n",
    "### 3.1 旧风格（`ERROR_SET_MODE`）\n",
    "- `orig`：$\\{I\\}\\cup\\{X_i,Y_i,Z_i\\}_{i=1}^L$（单比特 Pauli）\n",
    "- `E1`：在 `orig` 基础上加入若干二比特项（`XX, YY, XY, YX`，对所有 $i<j$）\n",
    "- `E2`：`E1` 的闭包（对所有 $A,B\\in E1$ 取乘积 $AB$）\n",
    "- `E3(L,r)`：$\\{I\\}\\cup\\{X_i,Y_i\\}\\cup Z_{\\le r}$，其中 $Z_{\\le r}$ 是对至多 $r$ 个比特的 $Z$ 乘积（所有组合）\n",
    "\n",
    "### 3.2 新风格（按“表格规格”）\n",
    "通过 `build_error_set_from_table_spec(L,K,d,r)`：\n",
    "- `d='2'`：等价于 `orig`\n",
    "- `d='asym', r=None`：一个“混合非对称”集合  \n",
    "  $\\{I\\}\\cup\\{X_i,Y_i,Z_i\\}\\cup\\{XX,ZZ,XZ,ZX\\}$\n",
    "- `d='asym', r>=1`：等价于 `E3(L,r)`\n",
    "\n",
    "这类“非对称”误差集常用于模拟 **相位翻转 (Z) 与位翻转 (X/Y)** 发生概率不同的信道结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29057c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. Base Error Sets =====\n",
    "def error_set_orig(L):\n",
    "    E = [identity_n(L)]\n",
    "    for i in range(1, L+1):\n",
    "        E += [sigmax(i, L), sigmay(i, L), sigmaz(i, L)]\n",
    "    return E\n",
    "\n",
    "def error_set_E1(L):\n",
    "    E = [identity_n(L)]\n",
    "    for i in range(1, L+1):\n",
    "        E += [sigmax(i, L), sigmay(i, L), sigmaz(i, L)]\n",
    "    for i, j in combinations(range(1, L+1), 2):\n",
    "        E.append(sigmax(i, L) @ sigmax(j, L))\n",
    "        E.append(sigmay(i, L) @ sigmay(j, L))\n",
    "        E.append(sigmax(i, L) @ sigmay(j, L))\n",
    "        E.append(sigmay(i, L) @ sigmax(j, L))\n",
    "    return E\n",
    "\n",
    "def error_set_E2(L):\n",
    "    E1 = error_set_E1(L)\n",
    "    return [A @ B for A in E1 for B in E1]\n",
    "\n",
    "def error_set_E3(L, r):\n",
    "    E = [identity_n(L)]\n",
    "    for i in range(1, L+1):\n",
    "        E += [sigmax(i, L), sigmay(i, L)]\n",
    "    for w in range(1, min(r, L)+1):\n",
    "        for idxs in combinations(range(1, L+1), w):\n",
    "            Zprod = identity_n(L)\n",
    "            for j in idxs:\n",
    "                Zprod = Zprod @ sigmaz(j, L)\n",
    "            E.append(Zprod)\n",
    "    return E\n",
    "\n",
    "# ===== 3. Table-spec Error Sets =====\n",
    "def error_set_asym_mixed(L):\n",
    "    \"\"\"{I} U {X_i,Y_i,Z_i} U {XX, ZZ, XZ, ZX for i<j}\"\"\"\n",
    "    E = [identity_n(L)]\n",
    "    for i in range(1, L+1):\n",
    "        E += [sigmax(i, L), sigmay(i, L), sigmaz(i, L)]\n",
    "    for i, j in combinations(range(1, L+1), 2):\n",
    "        E.append(sigmax(i, L) @ sigmax(j, L))  # XX\n",
    "        E.append(sigmaz(i, L) @ sigmaz(j, L))  # ZZ\n",
    "        E.append(sigmax(i, L) @ sigmaz(j, L))  # XZ\n",
    "        E.append(sigmaz(i, L) @ sigmax(j, L))  # ZX\n",
    "    return E\n",
    "\n",
    "def build_error_set_from_table_spec(L, K, d, r):\n",
    "    \"\"\"\n",
    "    d='2'    -> {I} U {X_i,Y_i,Z_i}\n",
    "    d='asym' & r is None -> {I} U {X_i,Y_i,Z_i} U {XX,ZZ,XZ,ZX}\n",
    "    d='asym' & r>=1     -> {I} U {X_i,Y_i} U Z_{<=r}\n",
    "    \"\"\"\n",
    "    d = str(d).lower()\n",
    "    if d in ['2', 'two', 'sym', 'symmetric']:\n",
    "        return error_set_orig(L)\n",
    "    if d in ['asym', 'asymmetric']:\n",
    "        if (r is None) or (str(r).strip() == '' or str(r).lower() == 'none'):\n",
    "            return error_set_asym_mixed(L)\n",
    "        r = int(r)\n",
    "        if r < 1:\n",
    "            raise ValueError(\"For d='asym', r must be >=1 or None.\")\n",
    "        return error_set_E3(L, r)\n",
    "    raise ValueError(\"TABLE_D must be '2' or 'asym'.\")\n",
    "\n",
    "def build_error_set(mode, L, r=None):\n",
    "    mode = mode.lower()\n",
    "    if mode == 'orig': return error_set_orig(L)\n",
    "    if mode == 'e1':   return error_set_E1(L)\n",
    "    if mode == 'e2':   return error_set_E2(L)\n",
    "    if mode == 'e3':\n",
    "        if r is None: raise ValueError(\"E3 requires integer r.\")\n",
    "        return error_set_E3(L, r)\n",
    "    raise ValueError(f\"Unknown ERROR_SET_MODE: {mode}\")\n",
    "\n",
    "# quick check\n",
    "if USE_TABLE_SPEC:\n",
    "    Error_set = build_error_set_from_table_spec(L=L, K=TABLE_K, d=TABLE_D, r=TABLE_R)\n",
    "    mode_desc = f\"table_spec(d={TABLE_D}, r={TABLE_R}, n={L}, K={TABLE_K})\"\n",
    "else:\n",
    "    Error_set = build_error_set(ERROR_SET_MODE, L, r=(TABLE_R if ERROR_SET_MODE.lower()=='e3' else None))\n",
    "    mode_desc = ERROR_SET_MODE\n",
    "\n",
    "print(\"[info] mode =\", mode_desc)\n",
    "print(\"[info] |Error_set| =\", len(Error_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795f27d",
   "metadata": {},
   "source": [
    "## 4. 从误差集合到 KL 约束算符列表（`op_list`）\n",
    "\n",
    "我们真正拿来约束码空间的算符列表记为 $\\{O_k\\}_{k=1}^M$。\n",
    "\n",
    "- **检测级（detect）**  \n",
    "  直接用误差集合中的每个误差算符（可选丢掉 $I$）：\n",
    "  \\[\n",
    "  O_k \\in \\mathcal{E}\\setminus\\{I\\}.\n",
    "  \\]\n",
    "\n",
    "- **纠错级（correct）**  \n",
    "  KL 条件要求对所有 $E_a^\\dagger E_b$ 都满足投影后为标量倍数。  \n",
    "  对 Pauli 类（酉、Hermitian up to phase）算符，脚本用一个简单构造：\n",
    "  \\[\n",
    "  O_{(a,b)} = E_a E_b,\\quad a<b.\n",
    "  \\]\n",
    "  这会形成更大的约束集合（通常比 detect 难很多）。\n",
    "\n",
    "脚本中的 `feasible` 判据为：\n",
    "\\[\n",
    "\\text{offdiag}+\\text{diag} < \\texttt{constraint_threshold}.\n",
    "\\]\n",
    "其中 offdiag/diag 由下一节的损失函数定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 4. KL operator lists =====\n",
    "def distance_3_error_set(error_set):\n",
    "    ret = []\n",
    "    n = len(error_set)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            ret.append(error_set[i] @ error_set[j])\n",
    "    return ret\n",
    "\n",
    "def is_identity(A, L):\n",
    "    return (A - identity_n(L)).nnz == 0\n",
    "\n",
    "def build_op_list_for_KL(Error_set, L, KL_LEVEL, drop_I_in_detect=True):\n",
    "    level = KL_LEVEL.lower()\n",
    "    if level == 'detect':\n",
    "        return [A for A in Error_set if not (drop_I_in_detect and is_identity(A, L))]\n",
    "    if level == 'correct':\n",
    "        return distance_3_error_set(Error_set)\n",
    "    raise ValueError(\"KL_LEVEL must be 'detect' or 'correct'.\")\n",
    "\n",
    "op_list_sparse = build_op_list_for_KL(Error_set, L, KL_LEVEL, drop_I_in_detect=DROP_IDENTITY_IN_DETECT)\n",
    "print(\"[info] |op_list| =\", len(op_list_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12937371",
   "metadata": {},
   "source": [
    "## 5. 可选：循环平移对称（cyclic symmetry, k=0）嵌入\n",
    "\n",
    "这是脚本新增的一个重要功能：把搜索空间从全 Hilbert 空间 $\\mathbb{C}^{2^L}$ 限制到 **循环不变子空间**（translation-invariant sector）。\n",
    "\n",
    "### 5.1 直觉\n",
    "定义循环平移算符 $T$：\n",
    "\\[\n",
    "T\\,|b_1 b_2 \\dots b_L\\rangle = |b_L b_1 \\dots b_{L-1}\\rangle.\n",
    "\\]\n",
    "`k=0` 扇区对应 $T$ 的本征值为 $1$ 的子空间，即满足 $T|\\psi\\rangle=|\\psi\\rangle$。\n",
    "\n",
    "### 5.2 构造方式（按轨道 orbit）\n",
    "对任意计算基态 $|x\\rangle$，考虑其在循环移位下的轨道：\n",
    "\\[\n",
    "\\mathcal{O}(x) = \\{x, Tx, T^2x,\\dots\\}.\n",
    "\\]\n",
    "在 `k=0` 子空间里，一个自然基向量是该轨道上的等幅叠加：\n",
    "\\[\n",
    "|\\Phi_{\\mathcal{O}}\\rangle = \\frac{1}{\\sqrt{|\\mathcal{O}|}}\\sum_{y\\in \\mathcal{O}} |y\\rangle.\n",
    "\\]\n",
    "把所有不同轨道的 $|\\Phi_{\\mathcal{O}}\\rangle$ 作为列向量堆叠起来，就得到嵌入矩阵\n",
    "\\[\n",
    "S\\in\\mathbb{C}^{2^L\\times N_c},\n",
    "\\]\n",
    "其中 $N_c$ 是轨道数量（也就是 `k=0` 子空间维度）。脚本最后还做了一次 QR 以数值稳健地正交化。\n",
    "\n",
    "### 5.3 在优化里的作用\n",
    "如果我们让 $U_{\\rm eff}\\in\\mathbb{C}^{N_c\\times K}$，则全空间码基为：\n",
    "\\[\n",
    "U_{\\rm full} = S\\,U_{\\rm eff}.\n",
    "\\]\n",
    "并且每个算符在有效空间中的表示是：\n",
    "\\[\n",
    "O_{\\rm eff} = S^\\dagger O S.\n",
    "\\]\n",
    "这样所有优化都在更小的 $N_c$ 维空间里进行，往往快很多。\n",
    "\n",
    "> 注意：开启 `USE_CYCLIC_SYM=True` 后，必须满足 `CODE_K <= N_c`，否则无解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 5. Cyclic-invariant (k=0) embedding =====\n",
    "def _int_to_bits(i: int, L: int) -> tuple:\n",
    "    return tuple((i >> (L-1-p)) & 1 for p in range(L))\n",
    "\n",
    "def _bits_to_int(bits: tuple) -> int:\n",
    "    v = 0\n",
    "    for b in bits:\n",
    "        v = (v << 1) | b\n",
    "    return v\n",
    "\n",
    "def _rotate_tuple(t: tuple, r: int = 1) -> tuple:\n",
    "    n = len(t); r %= n\n",
    "    return t[-r:] + t[:-r] if r else t\n",
    "\n",
    "def _orbit_indices(i0: int, L: int) -> list:\n",
    "    \"\"\"Return the cyclic orbit of bitstring i0 (as integer indices).\"\"\"\n",
    "    x = _int_to_bits(i0, L)\n",
    "    seen = {}\n",
    "    cur = x; r = 0\n",
    "    while cur not in seen:\n",
    "        seen[cur] = r\n",
    "        r += 1\n",
    "        cur = _rotate_tuple(cur, 1)\n",
    "    orb = [w for w,_ in sorted(seen.items(), key=lambda kv: kv[1])]\n",
    "    return [_bits_to_int(w) for w in orb]\n",
    "\n",
    "def build_cyclic_k0_embedding(L: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return S in C^{2^L x N_c}, columns are normalized equal-amplitude orbit superpositions.\n",
    "    Numerically, we QR-orthonormalize at the end for robustness.\n",
    "    \"\"\"\n",
    "    N = 2**L\n",
    "    used_reps = set()\n",
    "    columns = []\n",
    "    for i in range(N):\n",
    "        orb = _orbit_indices(i, L)\n",
    "        rep = min(orb)\n",
    "        if rep in used_reps:\n",
    "            continue\n",
    "        used_reps.add(rep)\n",
    "        s = len(orb)\n",
    "        col = np.zeros(N, dtype=np.complex128)\n",
    "        amp = 1.0/np.sqrt(s)\n",
    "        for idx in orb:\n",
    "            col[idx] = amp\n",
    "        columns.append(col)\n",
    "    S = np.stack(columns, axis=1)  # [N, N_c]\n",
    "    Q, _ = np.linalg.qr(S)\n",
    "    return Q.astype(np.complex128)\n",
    "\n",
    "def describe_cyclic_embedding(L: int) -> str:\n",
    "    S = build_cyclic_k0_embedding(L)\n",
    "    return f\"cyclic-k0 subspace (n={L}, dim={S.shape[1]})\"\n",
    "\n",
    "embedding = None\n",
    "if USE_CYCLIC_SYM:\n",
    "    assert CYCLIC_SECTOR.lower() == 'k0', \"Only cyclic k=0 is implemented.\"\n",
    "    S = build_cyclic_k0_embedding(L)   # [2^L, N_c]\n",
    "    embedding = S\n",
    "    print(\"[info] cyclic embedding:\", S.shape, \"|\", describe_cyclic_embedding(L))\n",
    "    if CODE_K > S.shape[1]:\n",
    "        raise ValueError(f\"CODE_K={CODE_K} > N_c={S.shape[1]} (cyclic subspace dim). Reduce K or disable symmetry.\")\n",
    "else:\n",
    "    print(\"[info] cyclic embedding disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6357347",
   "metadata": {},
   "source": [
    "## 6. 优化变量：码空间等距嵌入 $U$（Stiefel 流形）\n",
    "\n",
    "我们用一个矩阵 $U\\in\\mathbb{C}^{N\\times K}$ 表示码空间的正交归一基（$N=2^L$），满足：\n",
    "\\[\n",
    "U^\\dagger U = I_K.\n",
    "\\]\n",
    "这就是 **复 Stiefel 流形** $\\mathrm{St}(N,K)$。\n",
    "\n",
    "令 $P = U U^\\dagger$ 为投影算符。对每个约束算符 $O_m$（来自上一节的 `op_list`），KL 条件希望：\n",
    "\\[\n",
    "U^\\dagger O_m U = \\lambda_m I_K.\n",
    "\\]\n",
    "脚本把这一目标分解成三个损失项：\n",
    "\n",
    "1. **Off-diagonal penalty**  \n",
    "   \\[\n",
    "   \\mathcal{L}_{\\text{off}}=\\sum_m \\|A_m-\\mathrm{diag}(A_m)\\|_F^2\n",
    "   \\]\n",
    "   逼迫 $A_m$ 变成对角矩阵；\n",
    "\n",
    "2. **Diagonal-equality penalty**  \n",
    "   取对角线实部 $d_{m,i}=\\mathrm{Re}(A_{m,ii})$，希望它们对 $i$ 不依赖（等于其均值）：\n",
    "   \\[\n",
    "   \\mathcal{L}_{\\text{diag}}=\\sum_m\\sum_i (d_{m,i}-\\bar d_m)^2.\n",
    "   \\]\n",
    "\n",
    "3. **Lambda shaping**（扫描 $\\lambda^{*2}$ 的关键）  \n",
    "   令 $\\lambda_m=\\bar d_m$（每个算符对应一个标量），则\n",
    "   \\[\n",
    "   \\|\\lambda\\|^2 = \\sum_m \\lambda_m^2.\n",
    "   \\]\n",
    "   当 `lambda_target = sqrt(lambda2)` 时，脚本用\n",
    "   \\[\n",
    "   \\mathcal{L}_\\lambda = (\\|\\lambda\\|^2 - \\lambda^{*2})^2\n",
    "   \\]\n",
    "   让解“贴近”指定的目标范数。\n",
    "\n",
    "总损失：\n",
    "\\[\n",
    "\\mathcal{L} = \\alpha(\\mathcal{L}_{\\text{off}}+\\mathcal{L}_{\\text{diag}})+\\mathcal{L}_\\lambda,\n",
    "\\]\n",
    "其中 `alpha = model.penalty`。\n",
    "\n",
    "> 重要：最终选择“可行解”时，只看 $\\mathcal{L}_{\\text{off}}+\\mathcal{L}_{\\text{diag}}$ 是否足够小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60321aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 6. Model (general K) with optional embedding =====\n",
    "class DummyModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Optimize U_eff on Stiefel(N_eff, K). If embedding S (N x N_eff) is provided:\n",
    "      - U_full = S @ U_eff\n",
    "      - We pre-project operators: O_eff = S^H O S (so optimization stays in N_eff).\n",
    "    For each operator O_m, define A_m = U_eff^H O_eff U_eff, ideally lambda_m * I_K.\n",
    "    \"\"\"\n",
    "    def __init__(self, op_list, penalty=1.0, embedding: np.ndarray = None):\n",
    "        super().__init__()\n",
    "\n",
    "        # sparse -> dense torch tensors: [M, N, N]\n",
    "        op_dense = torch.stack([torch.tensor(op.toarray(), dtype=torch.complex128) for op in op_list])\n",
    "\n",
    "        self.embedding = None\n",
    "        if embedding is not None:\n",
    "            S = torch.tensor(embedding, dtype=torch.complex128)    # [N, N_eff]\n",
    "            Sdag = S.T.conj()                                      # [N_eff, N]\n",
    "            # O_eff = S^H O S: [M, N_eff, N_eff]\n",
    "            op_eff = torch.einsum('ab,mbc,cd->mad', Sdag, op_dense, S)\n",
    "            self.op_list = op_eff\n",
    "            self.embedding = S\n",
    "            N_eff = S.shape[1]\n",
    "        else:\n",
    "            self.op_list = op_dense\n",
    "            N_eff = op_dense.shape[-1]\n",
    "\n",
    "        self.code_k = int(CODE_K)\n",
    "        if self.code_k > N_eff:\n",
    "            raise ValueError(f\"CODE_K={self.code_k} > N_eff={N_eff}. Reduce K or disable symmetry.\")\n",
    "\n",
    "        self.manifold = numqi.manifold.Stiefel(N_eff, self.code_k, dtype=torch.complex128)\n",
    "        self.lambda_target = None\n",
    "        self.penalty = float(penalty)\n",
    "\n",
    "    def set_lambda_target(self, x):\n",
    "        \"\"\"\n",
    "        x can be:\n",
    "          - None: disable lambda shaping\n",
    "          - 'min'/'max': minimize or maximize ||lambda||^2\n",
    "          - number (or array): target value(s)\n",
    "        \"\"\"\n",
    "        if x is None:\n",
    "            self.lambda_target = None\n",
    "        elif isinstance(x, str):\n",
    "            assert x in ['min', 'max']\n",
    "            self.lambda_target = x\n",
    "        else:\n",
    "            t = torch.tensor(x, dtype=torch.float64).reshape(-1)\n",
    "            self.lambda_target = t[0] if t.numel() == 1 else t\n",
    "\n",
    "    def forward(self, return_info=False):\n",
    "        U_eff = self.manifold()                           # [N_eff, K]\n",
    "        # broadcasting matmul: (K,N_eff) @ (M,N_eff,N_eff) @ (N_eff,K) -> (M,K,K)\n",
    "        A = U_eff.T.conj() @ self.op_list @ U_eff\n",
    "\n",
    "        # Off-diagonal penalty\n",
    "        diagA = torch.diagonal(A, dim1=1, dim2=2)         # [M, K]\n",
    "        A_off = A - torch.diag_embed(diagA)\n",
    "        loss_offdiag = (A_off.abs()**2).sum().real\n",
    "\n",
    "        # Diagonal-equality penalty (use real part)\n",
    "        diag_real = diagA.real                            # [M, K]\n",
    "        diag_mean = diag_real.mean(dim=1, keepdim=True)   # [M, 1]\n",
    "        loss_diag = ((diag_real - diag_mean)**2).sum()\n",
    "\n",
    "        # Lambda shaping\n",
    "        lambdas = diag_mean.squeeze(1)                    # [M]\n",
    "        if self.lambda_target is None:\n",
    "            loss_lambda = torch.tensor(0.0, dtype=torch.float64)\n",
    "        elif isinstance(self.lambda_target, str):\n",
    "            loss_lambda = torch.dot(lambdas, lambdas) if self.lambda_target == 'min' else -torch.dot(lambdas, lambdas)\n",
    "        elif self.lambda_target.numel() == 1:\n",
    "            loss_lambda = (torch.dot(lambdas, lambdas) - self.lambda_target**2)**2\n",
    "        else:\n",
    "            loss_lambda = torch.dot(lambdas - self.lambda_target, lambdas - self.lambda_target)\n",
    "\n",
    "        total = self.penalty*(loss_offdiag + loss_diag) + loss_lambda\n",
    "\n",
    "        if return_info:\n",
    "            if self.embedding is not None:\n",
    "                U_full = self.embedding @ U_eff\n",
    "            else:\n",
    "                U_full = U_eff\n",
    "            total = total, dict(\n",
    "                loss=(total, loss_offdiag, loss_diag, loss_lambda),\n",
    "                lambda_ab_ij=A,       # A in effective space\n",
    "                code=U_full,          # basis in full space\n",
    "                code_eff=U_eff        # basis in effective space\n",
    "            )\n",
    "        return total\n",
    "\n",
    "# Instantiate model\n",
    "model = DummyModel(op_list_sparse, embedding=embedding)\n",
    "model.penalty = 10.0\n",
    "print(\"[info] model built; penalty =\", model.penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8926a99",
   "metadata": {},
   "source": [
    "## 7. 主流程：扫描 $\\lambda^{*2}$，记录“可行最优”并保存图表\n",
    "\n",
    "脚本做的事情可以概括为：\n",
    "\n",
    "1. 对每个目标点 $\\lambda^{*2}\\in$ `lambda2_list`：\n",
    "   - 设定 `lambda_target = sqrt(lambda2)`；\n",
    "   - 用 `numqi.optimize.minimize` 在 Stiefel 流形上优化；\n",
    "   - 收集每次迭代的参数 `optim_x`，并**重新回放**计算四个损失 + 实现的 $\\|\\lambda\\|^2$；\n",
    "2. 以约束阈值判断可行：\n",
    "   - `feasible(row) := offdiag + diag < constraint_threshold`\n",
    "3. 对每个 $\\lambda^{*2}$ 选出 “lambda_loss 最小的可行解” 作为该点代表；\n",
    "4. 输出：\n",
    "   - 控制台打印每个目标点的最优可行值（含 `achieved_lambda2`）\n",
    "   - 画 `lambda_loss` vs `lambda2`\n",
    "   - 保存 `png` 图与 `csv` 摘要\n",
    "\n",
    "下面的代码基本等价于你脚本里的 `main()`，但我们把它封装成函数，方便在 Notebook 里重复调用或改参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae76ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 7. Main scan function =====\n",
    "def run_lambda2_scan(\n",
    "    model: DummyModel,\n",
    "    lambda2_list: np.ndarray,\n",
    "    optim_kwargs: dict,\n",
    "    constraint_threshold: float,\n",
    "    out_prefix: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run scan over target lambda2 values.\n",
    "    Return:\n",
    "      - fval_optim: [T,5] = [total, offdiag, diag, lambda_loss, achieved_lambda2] for best feasible point\n",
    "      - loss_histories: list of histories; each history is a list of rows like above for each iterate\n",
    "    \"\"\"\n",
    "    loss_histories = []\n",
    "    codes = []\n",
    "\n",
    "    for lambda2 in lambda2_list:\n",
    "        model.set_lambda_target(np.sqrt(float(lambda2)))\n",
    "        callback = numqi.optimize.MinimizeCallback(print_freq=500)\n",
    "        _ = numqi.optimize.minimize(model, callback=callback, **optim_kwargs)\n",
    "\n",
    "        # replay every iterate to compute achieved ||lambda||^2 precisely\n",
    "        with torch.no_grad():\n",
    "            hist = []\n",
    "            for h in callback.history_state:\n",
    "                numqi.optimize.set_model_flat_parameter(model, h['optim_x'])\n",
    "                loss, info = model(return_info=True)\n",
    "\n",
    "                A = info['lambda_ab_ij']                          # [M,K,K]\n",
    "                diagA = torch.diagonal(A, dim1=1, dim2=2).real    # [M,K]\n",
    "                lam_vec = diagA.mean(dim=1)                       # [M]\n",
    "                lam2_val = float(torch.dot(lam_vec, lam_vec))     # achieved ||lambda||^2\n",
    "\n",
    "                four_losses = [x.item() for x in info['loss']]    # [total, off, diag, lambda_loss]\n",
    "                hist.append(four_losses + [lam2_val])             # + achieved_lambda2\n",
    "            print('[scan] target lambda2 =', float(lambda2), '| iterates =', len(hist))\n",
    "            loss_histories.append(hist)\n",
    "\n",
    "        # save final code basis for this target\n",
    "        codes.append(model(return_info=True)[1]['code'])\n",
    "\n",
    "    # feasibility and selection\n",
    "    def feasible(row):\n",
    "        return (row[1] + row[2]) < constraint_threshold\n",
    "\n",
    "    def best(history):\n",
    "        feas = [x for x in history if feasible(x)]\n",
    "        return [np.nan]*5 if len(feas)==0 else min(feas, key=lambda x: x[3])  # minimize lambda_loss\n",
    "\n",
    "    fval_optim = np.array([best(h) for h in loss_histories])  # [T, 5]\n",
    "\n",
    "    # report\n",
    "    print(\"\\n[report] Best feasible per target lambda2\")\n",
    "    print(\" idx | target_lambda2 | feas? | loss_total |  offdiag |    diag  | lambda_loss | achieved_lambda2\")\n",
    "    for i, (target_l2, hist) in enumerate(zip(lambda2_list, loss_histories)):\n",
    "        feas_hist = [x for x in hist if feasible(x)]\n",
    "        if not feas_hist:\n",
    "            print(f\"{i:4d} | {target_l2:14.6g} |  no  |     nan    |    nan  |    nan  |    nan     |      nan\")\n",
    "            continue\n",
    "        row = min(feas_hist, key=lambda x: x[3])\n",
    "        print(f\"{i:4d} | {target_l2:14.6g} | yes  | {row[0]:10.3e} | {row[1]:8.1e} | {row[2]:8.1e} | {row[3]:11.3e} | {row[4]:14.6g}\")\n",
    "\n",
    "    # plot: lambda_loss curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(lambda2_list, fval_optim[:, 3], label='lambda_loss (best feasible)')\n",
    "    ax.set_xlabel(r'$\\lambda^{*2}$')\n",
    "    ax.set_ylabel('lambda loss')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.4)\n",
    "    ax.yaxis.set_major_locator(LogLocator(base=10))\n",
    "    ax.yaxis.set_minor_formatter(ScalarFormatter())\n",
    "\n",
    "    max_constraint = np.nan_to_num(fval_optim[:,1] + fval_optim[:,2], nan=0).max()\n",
    "    sym_tag = \" | cyclic k=0\" if USE_CYCLIC_SYM else \"\"\n",
    "    mode_desc = f\"{'table_spec' if USE_TABLE_SPEC else ERROR_SET_MODE}(d={TABLE_D}, r={TABLE_R}, n={L}, K={TABLE_K})\"\n",
    "    ax.set_title(f\"Cyclic Codes vs lambda: constraint <= {max_constraint:.3g} | mode={mode_desc} | KL={KL_LEVEL} | K={CODE_K}{sym_tag}\")\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # optional save\n",
    "    if out_prefix is not None:\n",
    "        out_png = f\"{out_prefix}.png\"\n",
    "        fig.savefig(out_png, dpi=200)\n",
    "        print(f'[plot] saved -> {out_png}')\n",
    "\n",
    "        out_csv = f\"{out_prefix}.csv\"\n",
    "        data_csv = np.column_stack([\n",
    "            lambda2_list,\n",
    "            fval_optim[:,0],\n",
    "            fval_optim[:,1],\n",
    "            fval_optim[:,2],\n",
    "            fval_optim[:,3],\n",
    "            fval_optim[:,4],\n",
    "        ])\n",
    "        header = \"target_lambda2,total,offdiag,diag,lambda_loss,achieved_lambda2\"\n",
    "        np.savetxt(out_csv, data_csv, delimiter=\",\", header=header, comments=\"\")\n",
    "        print(f\"[save] summary -> {out_csv}\")\n",
    "\n",
    "    return fval_optim, loss_histories, codes\n",
    "\n",
    "# output name base (match original)\n",
    "sym_suffix = \"_cyclic\" if USE_CYCLIC_SYM else \"\"\n",
    "out_prefix = f\"n{L}_K{CODE_K}_{TABLE_D}_r{TABLE_R}_KL-{KL_LEVEL}{sym_suffix}\"\n",
    "\n",
    "print(\"[info] out_prefix =\", out_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d2292",
   "metadata": {},
   "source": [
    "## 8. 运行扫描（可能耗时）\n",
    "\n",
    "- 如果你打开了 `SMOKE_TEST=True`，这里会很快跑完并生成 `png/csv`。\n",
    "- 如果你使用原始默认 `lambda2_list`（100 个点）且 `num_repeat=50`，可能需要较长时间。\n",
    "\n",
    "运行后当前目录会生成：\n",
    "- `{out_prefix}.png`\n",
    "- `{out_prefix}.csv`\n",
    "\n",
    "你也可以把 `out_prefix` 改成带路径的字符串（例如 `\"results/myrun\"`），把输出放到某个文件夹里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ba785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 8. Run the scan =====\n",
    "# 注意：这一步可能很慢。建议先 SMOKE_TEST=True 试跑。\n",
    "fval_optim, loss_histories, codes = run_lambda2_scan(\n",
    "    model=model,\n",
    "    lambda2_list=lambda2_list,\n",
    "    optim_kwargs=optim_kwargs,\n",
    "    constraint_threshold=constraint_threshold,\n",
    "    out_prefix=out_prefix,\n",
    ")\n",
    "\n",
    "# fval_optim: [T,5] -> [total, offdiag, diag, lambda_loss, achieved_lambda2]\n",
    "print(\"[done] fval_optim shape =\", fval_optim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31a36a",
   "metadata": {},
   "source": [
    "## 9. （可选）后验检查：抽样查看 $U^\\dagger O U$\n",
    "\n",
    "为了更直观地验证 KL 结构，我们可以随机抽几个算符 $O_k$，打印矩阵\n",
    "\\[\n",
    "A_k = U^\\dagger O_k U\n",
    "\\]\n",
    "的前几行列，观察：\n",
    "- 是否近似对角；\n",
    "- 对角线实部是否接近常数；\n",
    "- off-diagonal Frobenius 范数是否很小。\n",
    "\n",
    "下面函数与原脚本一致，适配任意 $K$，也兼容开启 embedding 的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 9. Optional QC =====\n",
    "def qc_sample(model: DummyModel, idx_list=None, max_print=3):\n",
    "    \"\"\"Sample some operators and print U^H O_k U for quick inspection.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        loss, info = model(return_info=True)\n",
    "        A = info['lambda_ab_ij']    # [M,K,K] in effective space\n",
    "        M, K = A.shape[0], A.shape[-1]\n",
    "        if idx_list is None:\n",
    "            idx_list = np.random.choice(M, size=min(max_print, M), replace=False)\n",
    "        for k in idx_list:\n",
    "            Mk = A[k].cpu().numpy()\n",
    "            print(f\"[QC] op idx={k}, matrix shape={Mk.shape}, K={K}\")\n",
    "            sl = slice(0, min(K, 4))\n",
    "            print(np.round(Mk[sl, sl], 6))\n",
    "            off = Mk - np.diag(np.diag(Mk))\n",
    "            print(\"-- offdiag Fro norm^2:\", float((abs(off)**2).sum()))\n",
    "            d = np.real(np.diag(Mk))\n",
    "            print(\"-- diag real:\", np.round(d, 6), \" (std:\", float(d.std()), \")\")\n",
    "\n",
    "# Example usage (after running the scan, model holds the last solution):\n",
    "# qc_sample(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddc683",
   "metadata": {},
   "source": [
    "## 10. 常见改法与排错建议\n",
    "\n",
    "1. **想更严格的纠错级码**：把 `KL_LEVEL='correct'`。  \n",
    "   注意：`op_list` 会暴涨（$\\binom{|\\mathcal{E}|}{2}$ 级别），计算会变慢/内存更大。\n",
    "\n",
    "2. **想加入循环对称**：把 `USE_CYCLIC_SYM=True`。  \n",
    "   - 会先构造 `S`，并把每个算符投影到有效空间 `O_eff = S^H O S`；\n",
    "   - 如果报错 `CODE_K > N_c`，说明你想要的码维度超过了循环不变子空间的维度，需要减小 `K` 或关掉对称性。\n",
    "\n",
    "3. **速度/稳定性**：\n",
    "   - 第一次先 `SMOKE_TEST=True`；\n",
    "   - 把 `optim_kwargs['num_repeat']` 从 50 降到 5~10；\n",
    "   - `constraint_threshold` 放宽到 `1e-9` 或 `1e-8` 先找趋势，再收紧。\n",
    "\n",
    "4. **内存爆炸**：\n",
    "   - 主要发生在 `op_dense = torch.stack([... op.toarray() ...])`  \n",
    "     这里会把 `M` 个 $2^L\\times 2^L$ 矩阵一次性堆起来；\n",
    "   - 如果要做更大 $L$，通常要改成：\n",
    "     - 只保留必要的算符；\n",
    "     - 或利用张量积结构/稀疏结构/块结构在乘法里避免显式稠密化。\n",
    "\n",
    "---\n",
    "\n",
    "到这里，Notebook 已把原脚本的“讲义版”整理完毕：你可以直接改参数重复实验，也可以把某些 cell 抽出来做更系统的数值研究（例如对比不同误差集、不同 KL_LEVEL、不同对称扇区等）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
